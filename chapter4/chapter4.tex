Fully-autonomous drones are only as effective as the artificial intelligence software and decision-making protocols they use. SteelEagle is no different; its performance is tightly correlated with the sensor processing and control algorithms running on the edge. However, its offload-based design poses additional constraints: all sensor data from the drone is inherently latent and may have suboptimal throughput. Furthermore, cloudlets may be required to serve multiple drones, and may have to deal with changing network conditions that hamper bandwidth.

In this chapter, I will discuss my architecture for the SteelEagle backend. I will show how it addresses these unique problems and how it adapts to its network environment. In Section~\ref{sec:remote-intelligence-framework}, I outline the overall design of the system and its interaction with drone clients. In Section~\ref{sec:eval}, I evaluate the system on a few basic tasks to understand its capabilities.

\section{An Edge Intelligence Framework for Drones}
\label{sec:remote-intelligence-framework}
The SteelEagle backend is made up of three main modules: compute, command and control, and storage. To handle transmission between these modules and between the cloudlet and external clients, traffic is split into two channels, the data plane and the control plane. Each channel uses a different communication protocol to suit their specific quality-of-service demands. Figure~\ref{fig:sys-arch} shows the full system architecture. The overall system is characterized by two main data flows: the remote processing flow through the data plane and the remote control flow through the control plane. I will outline both to illustrate how the system operates.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{chapter4/FIGS/arch.png}
    \begin{captext}
    \small The remote processing flow, which handles the processing of the drone's sensor stream and the proliferation of generated results, is highlighted in blue. The remote control flow, which delivers all commander messages and auto-generated commands from the command and control module, is highlighted in red.
    \end{captext}
    \caption{SteelEagle System Architecture}
    \label{fig:sys-arch}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{chapter4/FIGS/gabriel.png}
    \begin{captext}
    \\[0.1cm]
    \small In the case of SteelEagle, the Wearable Device is replaced with a drone communicating over cellular. The User Guidance VM not only sends processing results back to the drone through the data server (as shown in Figure~\ref{fig:sys-arch}), but also stores results in the storage module.
    \end{captext}
    \caption{Gabirel Cognitive Assistance Model (Adapted from ~\cite{Ha2014})}
    \label{fig:gabriel-cognitive-assistance}
\end{figure}


\subsection{Remote Processing Flow}
Perhaps the most important data flow in SteelEagle is the remote processing flow, outlined in blue in Figure~\ref{fig:sys-arch}. The role of this flow is straightforward: retrieve sensor data and telemetry from the drone, run the requested algorithm by the current mission, return results to relevant clients, repeat. Yet there are additional considerations that complicate this seemingly simple picture. First, bandwidth is a precious resource for mobile systems, and availability may vary highly based on current network conditions~\cite{Forman1994}. For this reason, it is important that the stream retrieval portion of the data flow can cope with bandwidth constriction without introducing too much latency. Second, many DNNs require vast computational resources to run quickly. Some may not be able to sustain sufficient throughput to keep up with the drone's stream. If the data flow takes on multiple tenants without adapting its inference rate to model throughput, it could lead to queueing delay and thus added latency.

\subsubsection{Gabriel and the Cognitive Assistance Model}
To address both of these problems, the SteelEagle remote processing flow leverages the Gabriel Cognitive Assistance model~\cite{Ha2014}. Proposed in 2014, Gabriel is a bandwidth-adaptive edge intelligence system that provides near real-time sensor processing results to mobile clients (Figure~\ref{fig:gabriel-cognitive-assistance}). Gabriel is bandwidth-adaptive and model-throughput-adaptive thanks to its token-based flow control protocol. Token-based flow control is a technique for avoiding queueing delay in a client-producer server-consumer system using data objects called tokens. Tokens are a certificate that signal the server or client to act; if the server has a token, it has client data that needs to be processed and if the client has a token, it must send its most recently produced data to the server. 

At system start, a set number of tokens is agreed upon between the server (also called the control VM in Figure~\ref{fig:gabriel-cognitive-assistance}) and client. The server and client exchange these tokens based on their individual processing rates. For instance, if the client's send rate outpaces the server's processing rate, the server will be in possession of a large share of the tokens and vice versa. If no tokens remain on the client side, the client drops the current payload until it sees a new token. If no tokens remain on the server side, it waits to receive new client data. In this model, the client only ever sends the most recently produced payload which prevents the server from receiving highly latent data.

In Gabriel, each distinct sensor processing algorithm is called a ``cognitive engine''. Gabriel supports running several cognitive engines simultaneously, and manages their input data queues. Each cognitive engine is run in a separate container on the host machine, and is shipped data via an inter-process communication channel. Gabriel's tokens are shared among the engines which effectively bottlenecks the client send rate to the throughput of the fastest engine. On slower engines, queued data is dropped to ensure the latest data available is processed.

\subsubsection{SteelEagle Upgrades to Gabriel}
Gabriel is designed for mobile clients that have stable connections to the edge over WiFi. Due to this, underlying connections are made via websockets. Websockets are a point-to-point connection medium that are intended for web browser to server links. They are performant but must be modified to properly deal with disconnections. In the case of SteelEagle,  cellular links to the backend can be easily disrupted by drone motion or interference. This renders websockets sub-optimal. To fix this, SteelEagle replaces the underlying communication in Gabriel with ZeroMQ sockets that provide auto-reconnection among other quality-of-service guarantees~\cite{ZeroMQ}. Other connections within SteelEagle that are not Gabriel-regulated use pure ZeroMQ sockets (Figure~\ref{fig:sys-arch}).

Within SteelEagle, the Gabriel control VM is called the \textit{data server} and cognitive engines are managed by an entity called the \textit{compute module} (see Figure~\ref{fig:sys-arch}). In most cases, the compute module will spawn a pre-specified set of algorithms demanded by a drone mission at mission start. In the future, I envision that it may also support runtime addition and deletion of cognitive engines and dynamic scale-out at runtime to adapt to constrained computation resources or new mission parameters.

Unlike the default Gabriel implementation, SteelEagle supports multiple consumer clients of processing results (generated by the User Guidance VM in Figure~\ref{fig:gabriel-cognitive-assistance}). The main consumer of these results other than the drone is the storage module (see Figure~\ref{fig:sys-arch}). The storage module is a database responsible for logging all processed results in addition to the raw sensor and telemetry sent by the drone. This can be read by other monitoring clients such as the command and control module if needed for orchestration purposes.

\subsubsection{Supported Cognitive Engines}
As a result of its Gabriel-based design, SteelEagle supports a wide range of cognitive engines. To add new engines, users simply need to work within the Gabriel cognitive engine interface and connect to the Gabriel server~\cite{Ha2014}. The server will automatically configure the requested type of sensor stream and manage timely delivery of data to the engine. For initial evaluation purposes, I have configured two engines useful for drone operations: object detection and obstacle avoidance. I will detail their implementation in Section~\ref{sec:eval}.

\subsection{Remote Control Flow}
The remote control flow handles interactions between humans and SteelEagle drones. Within the SteelEagle ecosystem, since the drones are fully-autonomous, there are no conventional human pilots. Instead, humans who interact with SteelEagle drones are referred to as ``commanders''. Commanders create missions, send missions to aircraft, and monitor telemetry data to ensure continued safe operation. They also have the ability to manually pilot a connected aircraft in case of emergency. Figure~\ref{fig:commander} shows the commander UI. It provides continuous feedback on the progress of the mission on a map.  It also displays live sensor streams, including video, transmitted by the drone. It includes several buttons to upload missions, take manual control of one or more aircraft, and order one or more aircraft to return home.

Messages sent by commanders are aggregated in the command and control module (see Figure~\ref{fig:sys-arch}). Here, messages are relayed to the control server which then sends them to the target aircraft over a direct, unregulated socket connection. This is in contrast to the data server, which uses token-based flow control socket connections. The reason for this difference is that messages sent by commanders, especially emergency commands, are deemed to be high priority and must therefore be forced over the link as quickly as possible without any regard for bandwidth.

The command and control module also acts as an air traffic controller. That is, it manages the airspace inhabited by connected aircraft to ensure there are no mid-air collisions. For instance, it allocates non-intersecting altitude slices to different drones operating in the same mission area to ensure they are flying at different altitudes. The command and control module maintains up-to-date telemetry from all connected drone clients via the storage module and can therefore detect potential crashes before they happen.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{chapter4/FIGS/commander.png}
    \begin{captext}
    \small \textit{\textbf{1.} Active drones with displayed battery percentage, altitude, and GPS location, \textbf{2.} Selection of command recipients, \textbf{3.} Mission upload tool, \textbf{4.} Emergency and manual command buttons}
    \end{captext}
    \caption{Commander Interface}
    \label{fig:commander}
\end{figure}

\subsubsection{Drone Missions}
Prior to flight, a mission is planned using a toolchain that starts with Google MyMaps. The flight route can be specified using waypoints, line segments and polygons. Actions such as capturing images, tracking particular objects, or avoiding obstacles can be associated with parts of the route, and can be linked together to form a primitive behavior tree. Behavior trees are a common way of expressing missions in a variety of robotics settings~\cite{Ghouzli2023}. An offline compilation step, usually performed on a commander computer, transforms the high-level specification into low-level drone-specific runtime actions on the cloudlet and on the drone.  In the case of the Parrot Anafi-Galaxy Watch 4 prototype, the compiler output is expressed via Ground SDK API Java classes and packaged into an Android DEX file. A drone simulator can be used for testing and visualization of this output. 

In its current form, SteelEagle assumes a one-to-one correspondence of drones and missions. In particular, each drone executes its given mission in isolation, without cooperation. In future, to support swarm operations, this would change. For now, this simple abstraction provides enough for basic autonomous drone operations.

\input{chapter4/eval}